---
layout: post
title: KPI
---

I'm not sure I have seen a concept creating so many problems as KPI. I mean, is should be great shouldn't it? You want to improve the performance of something so you define a (or usually a selection of) KPI. Just listen to it, KPI. Key. Performance. Indicator. Not only an indicator of performance, but a **key** indicator of performance.

And so the game of defining KPIs begin. Say we develop software there are probably a whole bunch of KPIs we can come up with that could indicate how well we are doing. Here are some from the top of my mind (all taken from real life experiences)

* Release on time
* No more than X major bugs
* Support handled in Y amount of time

You can probably continue the list to include a whole bunch more but lets start with these. Of course we want to release software when expected, not have too many major problems using it and when a user of the software do have a problem we (usually) want to work with them to resolve it swiftly. If releases get major delays, there are huge amounts of major bugs or user problems are ignored that is a problem and an indicator of that something is wrong. Notice that I said they are _indicators_ of problems, perhaps not the actual problem themselves. Say we do have late releases, a whole bunch of major bugs and user support is abysmal what should we do about it?

Of course we should improve those numbers. From now on releases will be on time, There will be no more than three known major bugs and user problems must be responded to within four hours. And if that is not fulfilled there will be a reckoning (or at least no bonus). And since developers were just spitefully writing bad code slowly and support enjoyed ignoring requests we will now ... more about releasing something on time, not reporting major bugs and quickly responding to users with irrelevant data...
